---
title: "Order Flow Analysis"
author: "N.Naidoo, D. Chetty"
format: pdf
---
## Required libraries
```{r}
library(dplyr) # pipe operator
library(stringr) # string replace
library(lubridate)
library(ggplot2) #plots
library(zoo) #Resampling if needed
library(tseries) #ADF + KPSS tests
library(tidyr)
```


## Reading in data
```{r}
quote_data_all<-read.csv("XBTUSD_quotes_20171001_20171023.csv",header = TRUE)
trade_data_all<-read.csv("XBTUSD_trades_20171001_20171023.csv",header = TRUE)
```

## Formatting data 
```{r}
## so it matches research paper format
quote_data_all<-quote_data_all |> select(timestamp,bidPrice,bidSize,askPrice,askSize) 
quote_data_all<-quote_data_all |> rename(bidVolume=bidSize,askVolume=askSize)
trade_data_all<-trade_data_all |> select(timestamp,price,size,side)
trade_data_all<-trade_data_all |> rename(Volume=size)

quote_data_all <- quote_data_all %>%
  mutate(
    timestamp = str_replace(timestamp, "D", " "),
  )

trade_data_all <- trade_data_all %>%
  mutate(
    timestamp = str_replace(timestamp, "D", " "),
  )

```

 The intervals that are used for calculation of TFI and contemporaneous price 
change are the same as the intervals used in OFI modelling: 1 s, 10 s, 5 min, 10 min and 1 h.


```{r}
#Calculating mid price
quote_data_all <- quote_data_all |> 
  mutate(
    timestamp = ymd_hms(timestamp),
    mid_price = (bidPrice + askPrice) / 2
  )

```

```{r}
#Calculate OFI (One value per quote update)
quote_data_all <- quote_data_all |> 
  arrange(timestamp) |> 
  mutate(
    prev_bidPrice = lag(bidPrice),
    prev_bidVolume = lag(bidVolume),
    prev_askPrice = lag(askPrice),
    prev_askVolume = lag(askVolume),
    OFI = case_when(
      bidPrice >= prev_bidPrice ~ bidVolume,
      bidPrice < prev_bidPrice ~ -prev_bidVolume,
      TRUE ~ 0
    ) +
    case_when(
      askPrice >= prev_askPrice ~ prev_askVolume,
      askPrice < prev_askPrice ~ -askVolume,
      TRUE ~ 0
    )
  )

```


```{r}
#Format trade data for tfi
trade_data_all <- trade_data_all  |> 
  mutate(
    timestamp = ymd_hms(timestamp),
    signed_volume = if_else(side == "Buy", Volume, -Volume) 
  )

```

```{r}
# Function to Aggregate to Intervals
# 
# 
# Resample quotes to get mid-price change and OFI per interval
# 
# Resample trades to get TFI per interval

aggregate_ofi <- function(df, interval = "10 secs", tick_size = 0.1) {
  df |>
    mutate(interval_time = floor_date(timestamp, unit = interval)) |>
    group_by(interval_time) |>
    summarise(
      mid_price_start = first(mid_price),
      mid_price_end = last(mid_price),
      OFI = sum(OFI, na.rm = TRUE)
    ) |>
    mutate(mid_price_change = (mid_price_end - lag(mid_price_end)) / tick_size) |>
    drop_na()
}

aggregate_tfi <- function(trades, quotes, interval = "10 secs", tick_size = 0.1) {
  tfi <- trades |>
    mutate(interval_time = floor_date(timestamp, unit = interval)) |>
    group_by(interval_time) |>
    summarise(TFI = sum(signed_volume, na.rm = TRUE))

  mid <- quotes |>
    mutate(interval_time = floor_date(timestamp, unit = interval)) |>
    group_by(interval_time) |>
    summarise(mid_price = last(mid_price)) |>
    mutate(mid_price_change = (mid_price - lag(mid_price)) / tick_size)

  inner_join(mid, tfi, by = "interval_time") |> drop_na()
}

```


```{r}
# function to run lm an extraxt relevant stats
run_ols <- function(df, xvar, yvar) {
  formula <- as.formula(paste(yvar, "~", xvar))
  model <- lm(formula, data = df)
  s <- summary(model)
  c(
    alpha = s$coefficients[1, 1],
    beta = s$coefficients[2, 1],
    t_beta = s$coefficients[2, 3],
    r2 = s$r.squared,
    sig = (1 - s$coefficients[2, 4]) * 100
  )
}
```


## 5.1.1 Prices
Mid-price over time (Price chart)

```{r}
#| fig-width: 9
#| fig-height: 3
#Mid-price = (Bid price + Ask price) / 2
# Plot mid-price over time for the selected day.
#15th October 2017
# Prepare mid-price data for 15 Oct 2017
quote_data_day <- quote_data_all |>
  mutate(timestamp = ymd_hms(timestamp, tz = "UTC")) |>
  filter(as_date(timestamp) == as_date("2017-10-15")) |>
  mutate(mid_price = (bidPrice + askPrice) / 2)

# Define 3-hour breaks in UTC
start_time <- as.POSIXct("2017-10-15 03:00:00", tz = "UTC")
end_time   <- as.POSIXct("2017-10-15 21:00:00", tz = "UTC")
breaks_seq <- seq(from = start_time, to = end_time, by = "3 hours")

# Plot XBTUSD Mid-Price Series (15 Oct 2017)
ggplot(quote_data_day, aes(x = timestamp, y = mid_price, color = "midprice")) +
  geom_line() +
  scale_color_manual(values = c("midprice" = "blue")) +
  scale_x_datetime(
    breaks = breaks_seq,
    labels = format(breaks_seq, "%m.%d.%H", tz = "UTC"),
    timezone = "UTC"
  ) +
  labs(
    title = "",
    x = "Day of 15th October 2017 (dd.mm.hh)", y = "Mid-Price (USD)",
    color = NULL
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
     axis.title.x = element_text(margin = margin(t = 10)),
  axis.title.y = element_text(margin = margin(r = 10)),  
    panel.grid.major = element_line(color = "gray80"),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    legend.position = c(1, 1),
    legend.justification = c(1, 1),
    legend.background = element_rect(fill = "white", color = "black")
  )


#Mid-price plot: shows the price movements over the trading day

```

Mid-price change over time (Tick-to-tick MP chart)
```{r}
#| fig-width: 9
#| fig-height: 3
# Mid-price change = current mid-price âˆ’ previous mid-price.
# This gives tick-to-tick price movements.
# Plot the differenced series over time
# Ensure timestamps are in UTC
quote_data_day$timestamp <- as.POSIXct(quote_data_day$timestamp, tz = "UTC")

# Calculate tick-to-tick mid-price change
quote_data_day <- quote_data_day |>
  arrange(timestamp) |>
  mutate(mid_price_change = c(NA, diff(mid_price)))

# Define 3-hour breaks in UTC
start_time <- as.POSIXct("2017-10-15 03:00:00", tz = "UTC")
end_time   <- as.POSIXct("2017-10-15 21:00:00", tz = "UTC")
breaks_seq <- seq(from = start_time, to = end_time, by = "3 hours")

# Plot # Tick-to-Tick Mid-Price Change (15 Oct 2017)
ggplot(quote_data_day, aes(x = timestamp, y = mid_price_change, color = "dmidprice")) +
  geom_line() +
  scale_color_manual(values = c("dmidprice" = "orange")) +
  scale_x_datetime(
    breaks = breaks_seq,
    labels = format(breaks_seq, "%m.%d.%H", tz = "UTC"),
    timezone = "UTC"
  ) +
  labs(
    title = "",
    x = "Day of 15th October 2017 (dd.mm.hh)", y = "Mid-Price change (USD)",
    color = NULL
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title.x = element_text(margin = margin(t = 10)),
  axis.title.y = element_text(margin = margin(r = 10)),  
    panel.grid.major = element_line(color = "gray80"),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    legend.position = c(1, 1),
    legend.justification = c(1, 1),
    legend.background = element_rect(fill = "white", color = "black")
  )

```

Rolling volatility of mid-price changes (Moving Std Dev chart)
```{r}
#| fig-width: 9
#| fig-height: 3
# Proxy for volatility: moving standard deviation of mid-price changes.
# Rolling window: 1000 ticks, as per the paper.

# Ensure timestamps are in UTC
quote_data_day$timestamp <- as.POSIXct(quote_data_day$timestamp, tz = "UTC")

# Rolling volatility
quote_data_day$rolling_volatility <- rollapply(
  quote_data_day$mid_price_change,
  width = 1000,
  FUN = sd,
  fill = NA,
  align = "right"
)

# Breaks with UTC
start_time <- as.POSIXct("2017-10-15 03:00:00", tz = "UTC")
end_time   <- as.POSIXct("2017-10-15 21:00:00", tz = "UTC")
breaks_seq <- seq(from = start_time, to = end_time, by = "3 hours")

# Plot # Rolling Volatility (1000-tick window)
ggplot(quote_data_day, aes(x = timestamp, y = rolling_volatility, color = "vol")) +
  geom_line() +
  scale_color_manual(values = c("vol" = "darkgreen")) +
  scale_x_datetime(
    breaks = breaks_seq,
    labels = format(breaks_seq, "%m.%d.%H", tz = "UTC"),
    timezone = "UTC"
  ) +
  labs(
    title = "",
    x = "Day of 15th October 2017 (dd.mm.hh)", y = "Std. dev. of Mid-Price change",
    color = NULL
  ) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1),
    axis.title.x = element_text(margin = margin(t = 10)),
  axis.title.y = element_text(margin = margin(r = 10)),  
    panel.grid.major = element_line(color = "gray80"),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    legend.position = c(1, 1),
    legend.justification = c(1, 1),
    legend.background = element_rect(fill = "white", color = "black")
  )

#Rolling volatility plot: shows estimated volatility over the day

```

# 5.2  Order flow imbalance
Table 1: XBTUSD 1-Second Arrival Rate Statistics
```{r}
# 1-second intervals and count updates per second
arrival_rates <- quote_data_all |>
  mutate(timestamp = ymd_hms(timestamp),
         second_bucket = floor_date(timestamp, unit = "1 sec")) |>
  count(second_bucket, name = "updates_per_second")

# Summarize statistics
summary_table1 <- arrival_rates |>
  summarise(
    Mean = mean(updates_per_second),
    SD = sd(updates_per_second),
    Min = min(updates_per_second),
    `25%` = quantile(updates_per_second, 0.25),
    `50%` = median(updates_per_second),
    `75%` = quantile(updates_per_second, 0.75),
    Max = max(updates_per_second)
  )

print(summary_table1)
```

Figure 2: ACF of 10-Second Arrival Counts
Count the number of quote updates per 10-second bucket.
Compute and plot the autocorrelation function (ACF) of these counts.
```{r}
#| fig-width: 5
#| fig-height: 5
# Step 1: Aggregate updates into 10-second buckets
arrival_10s <- quote_data_all %>%
 mutate(timestamp = ymd_hms(timestamp),
       ten_sec_bucket = floor_date(timestamp, unit = "10 sec")) %>%
count(ten_sec_bucket, name = "updates_per_10s")

# Step 2: Compute ACF manually (limit to 10 lags)
acf_result <- acf(arrival_10s$updates_per_10s, lag.max = 10, plot = FALSE)

# # Step 3: Convert ACF to dataframe for ggplot
acf_df <- data.frame(
 Lag = as.numeric(acf_result$lag),
 ACF = as.numeric(acf_result$acf)
 )
# 
# # Step 4: Compute confidence bounds (approx Â±1.96/sqrt(N))
N <- length(arrival_10s$updates_per_10s)
conf_interval <- 1.96 / sqrt(N)

# Step 5: Plot as bars with red dashed confidence lines
library(scales)

# Plot as bars with adjusted axes and styling
ggplot(acf_df, aes(x = Lag, y = ACF)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.4) +
  geom_hline(yintercept = c(conf_interval, -conf_interval), linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  scale_x_continuous(
    breaks = 0:9,
    limits = c(-0.5, 9.5)  # Expand limits to avoid clipping bars at 0 and 9
  ) +
  scale_y_continuous(
    breaks = seq(0, 1, by = 0.1),
    limits = c(-0.05, 1.05),   # Ensure CI lines visible below 0.0
    expand = c(0, 0)
  ) +
  labs(title = "",
       x = "Lag",
       y = "Autocorrelation") +
  theme_minimal()
#Update Coutns ACF
```


Table 2: ADF Test on OFI Series
Perform the Augmented Dickey-Fuller (ADF) test on the OFI time series.
Report: ADF statistic, p-value, Critical values
```{r}

# Aggregate OFI into 10-second intervals
ofi_10s <- quote_data_all |>
  mutate(timestamp = ymd_hms(timestamp),
         interval_time = floor_date(timestamp, unit = "10 sec")) |>
  group_by(interval_time) |>
  summarise(OFI = sum(OFI, na.rm = TRUE)) |>
  ungroup()

# Clean NA values (if any)
ofi_series_10s <- na.omit(ofi_10s$OFI)

# Perform ADF test on non-differenced OFI (10s sampling)
adf_result <- adf.test(ofi_series_10s)


print(adf_result)
```

 Fig. 3  XBTUSD 10-s order flow imbalance ACF
```{r}
#| fig-width: 5
#| fig-height: 5
# Step 1: Aggregate OFI into 10-second intervals (signed sums)
ofi_10s <- quote_data_all %>%
  mutate(interval_time = floor_date(timestamp, unit = "10 sec")) %>%
  group_by(interval_time) %>%
  summarise(OFI = sum(OFI, na.rm = TRUE)) %>%
  ungroup()

# Step 2: Compute ACF on aggregated, signed OFI (non-differenced)
acf_ofi_result <- acf(ofi_10s$OFI, lag.max = 10, plot = FALSE)

# Step 3: Format ACF result for plotting
acf_ofi_df <- data.frame(
  Lag = as.numeric(acf_ofi_result$lag),
  ACF = as.numeric(acf_ofi_result$acf)
)

# Step 4: Calculate 95% confidence interval
N_ofi <- length(ofi_10s$OFI)
conf_interval_ofi <- 1.96 / sqrt(N_ofi)

# Step 5: Plot OFI ACF (same style as Silantyev's Figure 3)
ggplot(acf_ofi_df, aes(x = Lag, y = ACF)) +
  geom_bar(stat = "identity", fill = "steelblue", width = 0.4) +
  geom_hline(yintercept = c(conf_interval_ofi, -conf_interval_ofi), linetype = "dashed", color = "red") +
  geom_hline(yintercept = 0, linetype = "solid", color = "black") +
  scale_x_continuous(
    breaks = 0:9,
    limits = c(-0.5, 9.5)
  ) +
  scale_y_continuous(
    breaks = seq(-0.1, 1, by = 0.1),
    limits = c(-0.1, 1.05),
    expand = c(0, 0)
  ) +
  labs(title = "OFI 10-Second ACF",
       x = "Lag",
       y = "Autocorrelation") +
  theme_minimal()
```




Table 3:  Results: order flow imbalance and trade flow imbalance model parameter estimation

```{r}
#loop over the different time aggregations
intervals <- c("1 sec", "10 secs", "1 min", "5 mins", "10 mins", "1 hour")
results <- data.frame()

for (intv in intervals) {
  ofi_data <- aggregate_ofi(quote_data_all, interval = intv)
  tfi_data <- aggregate_tfi(trade_data_all, quote_data_all, interval = intv)

  ofi_stats <- run_ols(ofi_data, "OFI", "mid_price_change")
  tfi_stats <- run_ols(tfi_data, "TFI", "mid_price_change")

  results <- rbind(results, data.frame(
    interval = intv,
    alpha_OFI = ofi_stats["alpha"],
    beta_OFI = ofi_stats["beta"],
    t_beta_OFI = ofi_stats["t_beta"],
    r2_OFI = ofi_stats["r2"],
    sig_OFI = ofi_stats["sig"],
    alpha_TFI = tfi_stats["alpha"],
    beta_TFI = tfi_stats["beta"],
    t_beta_TFI = tfi_stats["t_beta"],
    r2_TFI = tfi_stats["r2"],
    sig_TFI = tfi_stats["sig"]
  ))
}

```

```{r}
print(results)
#write.csv(results, "table3_replication.csv", row.names = FALSE)
```

```{r}
#Stationarity test
adf.test(ofi_data$OFI)
kpss.test(ofi_data$OFI, null = "Level")

adf.test(tfi_data$TFI)
kpss.test(tfi_data$TFI, null = "Level")

```

